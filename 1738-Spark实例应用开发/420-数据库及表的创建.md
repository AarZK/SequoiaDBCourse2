---
show: step
version: 1.0 
---

## 课程介绍

本课程将介绍如何通过 jdbc 的方式在 Hive on Spark 中访问外部数据源。

#### 实验环境

当前实验的系统和软件环境如下：

* Ubuntu 16.04.6 LTS
* JDK version "1.8.0_172"
* SequoiaDB version: 3.4
* SequoiaSQL-MySQL version: 3.4
* Spark version: 2.4.3
* IntelliJ IDEA Community Version: 2019.3.4

#### 知识点

在 Hive on Spark 中支持 SQL 方式关联外部数据源，只要在 Spark 中创建了外部数据源的关联表，就可以按照 JDBC 标准通过 Spark 访问外部数据源。

在 Spark 中创建关联表只需要指定数据源，无需定义表结构，在关联时 Spark 会根据结构化数据源自动生成表结构。以关联 SequoiaDB 集合空间为例，创建关联表语法及参数说明如下：

```sql
create table employee
using com.sequoiadb.spark      --建表使用的连接驱动
options(
host 'sdbserver1:11810',       --协调节点 host
collectionspace 'sample',      --集合空间名
collection 'employee',         --集合名
user 'sdbadmin',               --用户名
password 'sdbadmin'            --密码
);
```

## 打开项目

#### 打开 IDEA

打开 IDEA 代码开发工具。

![1738-420-01](C:\Users\14620\Desktop\Spark开发课程\图片\lesson2\1738-420-01.png)

#### 打开 SCDD-Spark 项目

选择 Spark 课程项目

![1738-420-02](C:\Users\14620\Desktop\Spark开发课程\图片\lesson2\1738-420-02.png)

#### 打开当前实验的 Package

如图所示找到当前实验使用的程序所在 Package

![1738-420-03](C:\Users\14620\Desktop\Spark开发课程\图片\lesson2\1738-420-03.png)

#### Maven 依赖

当前实验中使用到的 Maven 依赖如下

![1738-420-04](C:\Users\14620\Desktop\Spark开发课程\图片\lesson2\1738-420-04.png)

## 关联 SequoiaDB 集合

程序将通过 MySQL 实例初始化 employee 表存储到 SequoiaDB 中，通过 Hive on Spark 建立和 SequoiaDB 的 employee 集合空间关联的表进行查询。

#### 打开 LinkTable 类

如图所示打开 com.sequoiadb.lesson.spark.lesson2_createtable.LinkTable 类准备编写代码

![1738-420-05](C:\Users\14620\Desktop\Spark开发课程\图片\lesson2\1738-420-05.png)

#### 创建关联表代码

通过 JDBC 提交建表语句关联 employee 集合

```java
// 初始化表
String dropTable =
        "DROP TABLE " +
                "IF " +
                "\tEXISTS employee";
// 调用HiveUtil的doDDL()方法初始化employee表
HiveUtil.doDDL(dropTable);
// 创建Spark表（关联 SequoiaDB 的 employee 集合）
String createLinkTable =
        "create table employee " +
                "using com.sequoiadb.spark  " +
                "options( " +
                "host 'sdbserver1:11810', " +
                "collectionspace 'sample', " +
                "collection 'employee', " +
                "user 'sdbadmin'," +
                "password 'sdbadmin'" +
                ")";
// 调用HiveUtil的doDDL()方法执行 sql 语句
HiveUtil.doDDL(createLinkTable);
// 查看Spark表结构
String getDesc=
        "desc employee";
// 调用HiveUtil的doDQL()方法查询表结构
System.out.println("正在获取关联表结构……");
HiveUtil.doDQL(getDesc);
// 查询Spark表数据
String queryTable = "select id,name,sex,birth,phone,email,position,address from employee";
// 调用HiveUtil的doDQL()方法查询Spark表数据
System.out.println("正在获取关联表数据……");
HiveUtil.doDQL(queryTable);
```

将上述代码粘贴至 LinkTale 类 linkTable 方法的 `TODO -- lesson2_createtable:code1` 注释处（20 行），粘贴后效果如下图所示：

![1738-420-06](C:\Users\14620\Desktop\Spark开发课程\图片\lesson2\1738-420-06.png)

## 运行程序

#### 运行主函数

右键点击 CreateTableMainTest 选择 `Run` 运行主函数

![1738-420-07](C:\Users\14620\Desktop\Spark开发课程\图片\lesson2\1738-420-07.png)

#### 运行结果



## 总结

经过本课程学习，我们可以通过 Hive on Spark 创建和 MySQL 实例关联的外表，并可以通过 jdbc 的方式访问  Hive on Spark 中的关联表。
