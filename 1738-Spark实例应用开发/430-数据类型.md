# 3 Spark SQL 数据类型

## 3.1 课程介绍

本课程将介绍 Spark SQL 支持的一些常见数据类型，以及 Spark SQL 数据类型和 SequoiaDB 数据类型的映射关系。并通过实践将 SequoiaDB 作为 Spark SQL 的外部数据源，通过 jdbc 访问 Spark 外表插入不同类型的数据，观察不同数据类型分别在 Spark SQL 和 SequoiaDB 中的存储情况。

### 3.1.1  实验环境

当前实验的系统和软件环境如下：

* Ubuntu 16.04.6 LTS
* SequoiaDB version: 5.0
* SequoiaSQL-MySQL version: 3.4
* openjdk version "1.8.0_242"
* IntelliJ IDEA Community Version: 2019.3.4
* spark version: 2.4.3

## 3.2 知识点

### 3.2.1 数据类型映射关系

| SequoiaDB 类型 | SparkSQL 类型 | SQL 实例类型            |
| -------------- | ------------- | ----------------------- |
| int32          | IntegerType   | int                     |
| int64          | LongType      | bigint                  |
| double         | DoubleType    | double                  |
| decimal        | DecimalType   | decimal                 |
| string         | StringType    | string                  |
| ObjectId       | StringType    | string                  |
| boolean        | BooleanType   | boolean                 |
| date           | DateType      | date                    |
| timestamp      | TimestampType | timestamp               |
| binary         | BinaryType    | binary                  |
| null           | NullType      | null                    |
| BSON(嵌套对象) | StructType    | struct < field:type,… > |
| array          | ArrayType     | array < type >          |

* 数组类型

  Spark 的 **ArrayType** 数据类型为由 elementType 类型元素组成的序列值。指定字段类型为 ArrayType 写法如下：

  ```sql
  字段名 array<数组元素类型>
  ```

* 结构化类型

  Spark 的 **StructType** 数据类型为一个拥有 **StructFields** (fields) 序列结构的值，StructField(name, dataType, nullable) 代表 StructType 中的一个字段，字段的名字通过 name 指定，dataType 指定field的数据类型，nullable 表示字段的值是否有null值。指定字段类型为 StructType 写法如下：

  ```sql
  字段名 struct<key:key类型,val:value类型>
  ```

  > 说明
  >
  > StructType 类型中可以嵌套其他类型，例如：
  >
  > ```sql
  > StructType struct<key:int,val:array<int>>
  > ```

### 3.2.2 直接访问 SequoiaDB

在使用 Spark SQL 时除了像第 2 章那样通过关联 MySQL 实例间接访问 SequoiaDB 外，还可以通过 SequoiaDB-Spark 连接器直接访问 SequoiaDB。以本实验中使用的 typelist 表为例：

<img src="https://raw.githubusercontent.com/AarZK/picstore/master/20200406170408.png" alt="image-20200405202218007" style="zoom: 80%;" />

SequoiaDB 中的集合对象（collection）本身是 `NoSQL` 的，所以如果想要通过 Spark SQL 关联 SequoiaDB 操作结构化数据，需要在建立表关联时定义表结构。

```sql
create table typelist(                       -- 定义表结构
IntegerType int,
LongType bigint,
DoubleType double,
DecimalType decimal(10,1),
StringType string,
BooleanType boolean,
DateType date,
TimestampType timestamp,
BinaryType binary,
ArrayType array<int>,
StructType struct<key:int,val:array<int>>    
) using com.sequoiadb.spark                  -- 使用 SequoiaDB-Spark 连接器
options(
host 'master:11810',                         -- 指定主机和节点
collectionspace 'sample',                    -- 指定集合空间
collection 'typelist'                        -- 指定集合
);
```

> 使用连接器需要确保 `$SPARK_HOME` 的 `jars` 目录下有 `spark-sequoiadb` jar 包

## 3.3 实验步骤

### 3.3.1 Maven 工程介绍

* 打开 SCDD-Spark 工程

  ![image-20200405221311363](https://raw.githubusercontent.com/AarZK/picstore/master/20200406170415.png)

* 当前实验使用到的 Maven 依赖

  ```xml
          <dependency>
              <!-- hive 的 jdbc 连接依赖 -->
              <groupId>org.apache.hive</groupId>
              <artifactId>hive-jdbc</artifactId>
              <version>1.2.1</version>
          </dependency>
  
          <dependency>
              <!-- hadoop 通用依赖 -->
              <groupId>org.apache.hadoop</groupId>
              <artifactId>hadoop-common</artifactId>
              <version>2.4.1</version>
          </dependency>
  
          <dependency>
              <!-- SequoiaDB java 连接器 -->
              <groupId>com.sequoiadb</groupId>
              <artifactId>sequoiadb-driver</artifactId>
              <version>3.2.1</version>
          </dependency>
  
          <dependency>
              <!-- 解析json -->
              <groupId>com.alibaba</groupId>
              <artifactId>fastjson</artifactId>
              <version>1.2.58</version>
          </dependency>
  ```

* 打开当前实验所在包

  ![image-20200405215959672](https://raw.githubusercontent.com/AarZK/picstore/master/20200406170411.png)

### 3.3.2 关联 SequoiaDB 集合

* step1：在 Spark SQL 中创建表和 SequoiaDB *已有集合* 关联

  ```java
          // drop 已有的 typelist 表
          String dropTable="drop table if exists typelist";
          // 调用 HiveUtil 工具累执行 sql
          HiveUtil.doDDL(dropTable);
          // 创建 SequoiaDB 集合的关联表
          String linkCollection=
                  "create table typelist(\n" +
                          "IntegerType int,\n" +
                          "LongType bigint,\n" +
                          "DoubleType double,\n" +
                          "DecimalType decimal(10,1),\n" +
                          "StringType string,\n" +
                          "BooleanType boolean,\n" +
                          "DateType date,\n" +
                          "TimestampType timestamp,\n" +
                          "BinaryType binary,\n" +
                          "ArrayType array<int>,\n" +
                          "StructType struct<key:int,val:array<int>>\n" +
                          ") using com.sequoiadb.spark \n" +
                          "options(\n" +
                          "host 'master:11810',\n" +
                          "collectionspace 'sample',\n" +
                          "collection 'typelist'\n" +
                          ")";
          // 调用 HiveUtil 工具累执行 sql
          HiveUtil.doDDL(linkCollection);
  ```

  将上述代码粘贴至 `!TODO -- lesson3_datatype:step1` 标签处

  ![image-20200405215449792](https://raw.githubusercontent.com/AarZK/picstore/master/20200406170410.png)

* step2：运行程序初始化 SequoiaDB 集合并将其与 typelist 表关联

  右键点击 Run 运行程序

  ![image-20200404210526454](https://raw.githubusercontent.com/AarZK/picstore/master/20200406170409.png)

  程序运行结果如下：

  ![image-20200405220448217](https://raw.githubusercontent.com/AarZK/picstore/master/20200406170412.png)

### 3.3.3 插入记录分别在 Spark 和 SequoiaDB 中查询

* step3：向 Spark 的 typelist 表中插入包含不同数据类型的记录

  ```java
          // 插入记录（不同类型字段）
          String insertSql =
                  "insert into typelist\n" +
                          "values(\n" +
                          "1,\n" +
                          "9223372036854775807,\n" +
                          "3.1415,\n" +
                          "3.14,\n" +
                          "\"abc\",\n" +
                          "true,\n" +
                          "current_date(),\n" +
                          "current_timestamp(),\n" +
                          "encode(\"qazwsxedc\",\"UTF-8\"),\n" +
                          "array(1,2,3),\n" +
                          "struct(123,array(1,2,3))\n" +
                          ")";
          // 调用 HiveUtil 工具累执行 sql 语句
          HiveUtil.doDML(insertSql);
  ```

  将上述代码粘贴至 `!TODO -- lesson3_datatype:step3` 标签处

  ![image-20200405220537118](https://raw.githubusercontent.com/AarZK/picstore/master/20200406170413.png)

* step4：运行程序分别查询 Spark 和 SequoiaDB 中的记录

  右键点击 `Run` 运行程序打印查询结果

  ![image-20200405221527270](https://raw.githubusercontent.com/AarZK/picstore/master/20200406170416.png)

  查询结果如下：

  ![image-20200405221123729](https://raw.githubusercontent.com/AarZK/picstore/master/20200406170414.png)

## 3.4 总结

通过本课程的学习我们了解了 Spark SQL 常见的数据类型以及它们和 SequoiaDB 支持的数据类型的映射关系，并可以通过创建外表的形式直接访问 SequoiaDB 集合数据。
